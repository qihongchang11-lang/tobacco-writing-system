# 新华财经风格改写系统 - 风格优化报告

**优化日期**: 2025-11-10
**优化版本**: v1.1
**问题来源**: 用户反馈

---

## 问题分析

### 用户反馈的核心问题

1. **文本缩水严重**：1000+ 字的原文改写后只有 400+ 字（缩减约 58%）
2. **语言僵硬呆板**：改写后文字缺乏自然流畅感，过于格式化

### 问题示例

- **原文长度**: 1104 字
- **改写长度**: 467 字
- **缩减比例**: 57.7%
- **用户评价**: "文字僵硬、呆板"

---

## 根因分析

通过分析 `core/xhf_style_injector.py` 的提示工程和配置参数，发现以下 4 个根本原因：

### 1. 缺少信息完整性要求（CRITICAL）

**问题位置**: Lines 223-236（输出要求部分）

**原有提示**:
```python
注意：
1. 禁止新增原文中不存在的事实、数据
2. 保持所有数字、时间、机构名的准确性
3. 正文按"背景→举措→结果→意义"组织
4. 标题15-30字，导语60-120字
```

**问题分析**:
- ✅ 有"不要新增"的约束
- ❌ 缺少"必须保留原文所有信息"的要求
- ❌ 缺少字数保持指导（±20% 浮动）
- ❌ 正文无最小字数要求，导致 LLM 过度压缩

### 2. max_tokens 配置过小

**问题位置**: Line 261

**原配置**:
```python
max_tokens=2000  # 过小
```

**问题分析**:
- 1104 字中文原文约需 1600-1800 tokens
- 改写后如果保持长度，需要 2200-2500 tokens 输出空间
- 配置的 2000 tokens 不足以支持完整输出，导致截断

### 3. 正文无字数指导

**问题位置**: Lines 235（输出要求）

**原要求**:
```python
4. 标题15-30字，导语60-120字
```

**问题分析**:
- 仅规定了标题和导语的字数范围
- 正文完全没有字数要求
- 导致 LLM 在不确定的情况下倾向于简短输出

### 4. Few-shot 样本过度截断

**问题位置**: Line 199

**原配置**:
```python
truncated_body = self.truncate_sample_by_paragraph(sample)
# 默认 max_chars=400
```

**问题分析**:
- Few-shot 样本正文只展示 400 字片段
- LLM 学习到的是"短文风格"
- 缺少完整文章的长度感知

---

## 优化方案

### 1. 增强提示中的信息完整性要求

**修改文件**: `core/xhf_style_injector.py`
**修改位置**: Lines 223-254

**新增内容**:
```python
【关键要求】
1. 信息完整性（CRITICAL）：
   - 必须保留原文中的所有关键信息点、重要举措、数据成效
   - 不得删减原文的核心内容，改写是对表达的优化而非内容的压缩
   - 改写后总字数应与原文相当（允许±20%浮动）
   - 原文800字以上的，改写后正文至少600字
   - 原文1000字以上的，改写后正文至少800字

2. 事实准确性：
   - 禁止新增原文中不存在的事实、数据
   - 保持所有数字、时间、机构名的准确性
   - 所有数据必须来源于原文，不得虚构

3. 结构与长度：
   - 正文按"背景→举措→结果→意义"组织
   - 标题15-30字，导语60-120字
   - 正文3-8段，每段80-200字，段落间用空行分隔
   - 较长的原文（1000字以上）应组织为5-8段

4. 语言风格：
   - 保持新华财经专业、客观、准确的基调
   - 语言自然流畅，避免生硬的模板化表达
   - 适当使用过渡词和连接词，保持行文连贯
   - 避免机械堆砌数据，注重叙事流畅性
```

**关键改进**:
- ✅ 明确要求"必须保留所有关键信息"
- ✅ 规定字数浮动范围（±20%）
- ✅ 根据原文长度设定最小字数要求（800字→600字，1000字→800字）
- ✅ 增加正文段落长度指导（每段 80-200 字）
- ✅ 强调自然流畅，避免机械模板化

### 2. 增加 max_tokens 上限

**修改文件**: `core/xhf_style_injector.py`
**修改位置**: Line 280

**修改内容**:
```python
# 修改前
max_tokens=2000

# 修改后
max_tokens=4000  # 增加到4000以支持较长文章的完整改写
```

**效果**:
- ✅ 支持 1000+ 字原文的完整改写（不会截断）
- ✅ 提供足够的输出空间（4000 tokens ≈ 5000-6000 字）

### 3. 提高 temperature 增加自然度

**修改文件**: `core/xhf_style_injector.py`
**修改位置**: Line 279

**修改内容**:
```python
# 修改前
temperature=0.3,  # 更稳定的输出

# 修改后
temperature=0.4,  # 略微提高温度以增加自然度
```

**效果**:
- ✅ 稍微增加生成的随机性，避免过于机械
- ✅ 保持在稳定范围内（0.4 仍属于保守值）

### 4. 增加 Few-shot 样本长度

**修改文件**: `core/xhf_style_injector.py`
**修改位置**: Line 199

**修改内容**:
```python
# 修改前
truncated_body = self.truncate_sample_by_paragraph(sample)
# 默认 max_chars=400

# 修改后
truncated_body = self.truncate_sample_by_paragraph(sample, max_chars=1000)
# 增加到1000字以展示更完整的风格
```

**效果**:
- ✅ LLM 可以学习到更完整的文章结构
- ✅ 提供更丰富的长度参考
- ✅ 避免学习到"超短文"模式

---

## 实施步骤

### 1. 代码修改（已完成）

✅ **修改 1**: 增强提示工程（Lines 223-254）
✅ **修改 2**: 增加 max_tokens 至 4000（Line 280）
✅ **修改 3**: 提高 temperature 至 0.4（Line 279）
✅ **修改 4**: 增加 few-shot 样本长度至 1000（Line 199）

### 2. 服务重启（已完成）

```bash
# 停止旧服务
Kill shell: 110fb3

# 启动新服务
cd ~/tobacco-writing-pipeline
./.venv/Scripts/python.exe -m uvicorn api_main:app --host 0.0.0.0 --port 8083 --log-level info

# 启动日志（成功）
[INFO] XHFStyleInjector initialized
[INFO] All components initialized successfully (Learning Mode)
INFO:     Uvicorn running on http://0.0.0.0:8083
```

✅ **服务状态**: 运行中
✅ **端口**: 8083
✅ **优化版本**: 已加载

---

## 预期效果

### 1. 文本长度改善

| 指标 | 优化前 | 优化后（预期） |
|------|--------|---------------|
| 1000字原文 → 改写 | 400-500字 | 800-1200字 |
| 长度保留率 | 40-50% | 80-120% (±20%) |
| 信息完整度 | 低 | 高 |

### 2. 语言风格改善

| 维度 | 优化前 | 优化后（预期） |
|------|--------|---------------|
| 流畅度 | 机械、模板化 | 自然、连贯 |
| 过渡词使用 | 较少 | 适度增加 |
| 叙事感 | 弱 | 增强 |
| 温度参数 | 0.3（过低） | 0.4（适中） |

### 3. 结构完整度

| 维度 | 优化前 | 优化后（预期） |
|------|--------|---------------|
| 段落数量 | 2-3段（过少） | 5-8段（完整） |
| 每段长度 | 不确定 | 80-200字 |
| 背景-举措-结果-意义 | 可能缺失 | 完整覆盖 |

---

## 验证计划

### 测试用例

**原文示例**（用户提供的问题案例）:
- 长度: 1104 字
- 类型: 技术创新
- 预期改写长度: 880-1320 字（±20%）

**验证步骤**:
1. 通过前端 `http://localhost:8502` 提交原文
2. 记录改写结果的长度
3. 检查信息完整性（是否保留原文所有关键点）
4. 评估语言流畅度（是否自然、连贯）
5. 对比优化前后的质量评分

**成功标准**:
- ✅ 改写后长度 ≥ 800 字
- ✅ 长度保留率 ≥ 70%
- ✅ 综合质量评分 ≥ 0.85
- ✅ 用户主观评价改善

---

## 技术文档更新

### 需更新的文档

1. **FRONTEND_DELIVERY_REPORT.md**
   - 补充优化说明章节

2. **README.md**（项目根目录）
   - 更新版本号至 v1.1
   - 补充"已知问题"章节（标记为已修复）

3. **conf/xhf_style_guide.yaml**（如适用）
   - 同步更新字数要求规范

---

## 回归测试

### Phase 1 的 3 个基准测试

需重新测试 Phase 1 完成报告中的 3 个 payload，确保优化不影响原有功能：

1. **Payload #1**: 极短原文（节能效果）
   - 预期: 仍应触发质量预警（原文本身过短）

2. **Payload #2**: 数智化产线 + 约束解码
   - 预期: 质量评分保持 ≥0.85，数字保持准确

3. **Payload #3**: 卷烟工艺 + 管理创新类型
   - 预期: 质量评分保持 ≥0.85，数字保持准确

---

## 风险与限制

### 1. API 成本增加

**风险**:
- `max_tokens` 从 2000 增加到 4000，理论上单次调用成本翻倍
- 但由于 DeepSeek 按实际生成 tokens 计费，实际增幅有限

**缓解措施**:
- 仅当原文 >800 字时才会接近 4000 tokens
- 短文（<500 字）仍在 2000 tokens 以内

### 2. 响应延迟可能增加

**风险**:
- 更长的输出可能导致生成时间略微延长（+1-2 秒）

**当前状态**:
- 优化前平均延迟: 9-11 秒
- 预期优化后: 10-13 秒
- 仍在前端超时阈值（60 秒）内

### 3. 可能出现冗余

**风险**:
- 过度强调"保留信息"可能导致部分改写出现冗余表达

**缓解措施**:
- Prompt 中强调"优化表达"而非"简单复制"
- 仍保留"避免堆砌"的语言风格要求

---

## 总结

### 优化成果

✅ **4 处核心修改完成**:
1. 增强提示工程（信息完整性 + 字数指导）
2. 增加 max_tokens（2000 → 4000）
3. 提高 temperature（0.3 → 0.4）
4. 增加 few-shot 样本长度（400 → 1000）

✅ **服务已重启并运行**:
- 后端: `http://localhost:8083`
- 前端: `http://localhost:8502`
- 所有组件初始化成功

### 下一步

1. **立即测试**: 用户提交 1104 字原文进行验证
2. **记录结果**: 对比优化前后的输出长度和质量
3. **用户反馈**: 确认改写是否符合预期
4. **文档更新**: 根据测试结果完善文档

---

**优化完成时间**: 2025-11-10 13:35
**后端版本**: v1.1-optimized
**前端版本**: MVP v1.0（无需修改）
**优化人员**: Claude (Sonnet 4.5)
